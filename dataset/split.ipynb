{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Load and Parse the CoNLL Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the CoNLL data from a text file\n",
    "def load_conll_data(file_path):\n",
    "    sentences = []\n",
    "    sentence = []\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if line == \"\":\n",
    "                if sentence:\n",
    "                    sentences.append(sentence)\n",
    "                    sentence = []\n",
    "            else:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= 2:  # Ensure there's both token and tag\n",
    "                    sentence.append((parts[0], parts[-1])) # Last column contains the tag\n",
    "    if sentence:\n",
    "        sentences.append(sentence)  # Add last sentence if the file ends without a newline\n",
    "    \n",
    "    return sentences\n",
    "\n",
    "# Load the dataset\n",
    "conll_file_path = \"dataset_conll.txt\"\n",
    "sentences = load_conll_data(conll_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Convert to Sentence-Level Dataset with Multilabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags</th>\n",
       "      <th>entity_types</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[(A, B-Event), (passenger, I-Event), (aircraft...</td>\n",
       "      <td>[A, passenger, aircraft, is, approaching, ., D...</td>\n",
       "      <td>[B-Event, I-Event, I-Event, I-Event, E-Event, ...</td>\n",
       "      <td>[NonEvent, Event]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[(A, B-Event), (passenger, I-Event), (aircraft...</td>\n",
       "      <td>[A, passenger, aircraft, is, nearby, ., Fly, w...</td>\n",
       "      <td>[B-Event, I-Event, I-Event, I-Event, E-Event, ...</td>\n",
       "      <td>[NonEvent, Event]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[(Abnormal, B-Event), (compass, I-Event), (fun...</td>\n",
       "      <td>[Abnormal, compass, function, or, GPS, signal,...</td>\n",
       "      <td>[B-Event, I-Event, I-Event, I-Event, I-Event, ...</td>\n",
       "      <td>[Event]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[(Accelerator, B-Event), (is, I-Event), (Over,...</td>\n",
       "      <td>[Accelerator, is, Over, Range, .]</td>\n",
       "      <td>[B-Event, I-Event, I-Event, E-Event, O]</td>\n",
       "      <td>[Event]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[(Account, B-NonEvent), (not, I-NonEvent), (lo...</td>\n",
       "      <td>[Account, not, logged, in, ., Flight, altitude...</td>\n",
       "      <td>[B-NonEvent, I-NonEvent, I-NonEvent, E-NonEven...</td>\n",
       "      <td>[NonEvent, Event]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>[(Your, B-Event), (aircraft, I-Event), (is, I-...</td>\n",
       "      <td>[Your, aircraft, is, at, the, boundary, of, an...</td>\n",
       "      <td>[B-Event, I-Event, I-Event, I-Event, I-Event, ...</td>\n",
       "      <td>[NonEvent, Event]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>574</th>\n",
       "      <td>[(Your, B-Event), (aircraft, I-Event), (is, I-...</td>\n",
       "      <td>[Your, aircraft, is, at, the, boundary, of, an...</td>\n",
       "      <td>[B-Event, I-Event, I-Event, I-Event, I-Event, ...</td>\n",
       "      <td>[NonEvent, Event]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575</th>\n",
       "      <td>[(Your, B-Event), (aircraft, I-Event), (is, I-...</td>\n",
       "      <td>[Your, aircraft, is, flying, in, an, Altitude,...</td>\n",
       "      <td>[B-Event, I-Event, I-Event, I-Event, I-Event, ...</td>\n",
       "      <td>[NonEvent, Event]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>576</th>\n",
       "      <td>[(Your, B-Event), (palm, I-Event), (is, I-Even...</td>\n",
       "      <td>[Your, palm, is, too, close, to, the, aircraft...</td>\n",
       "      <td>[B-Event, I-Event, I-Event, I-Event, I-Event, ...</td>\n",
       "      <td>[NonEvent, Event]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>577</th>\n",
       "      <td>[(Your, B-Event), (palm, I-Event), (is, I-Even...</td>\n",
       "      <td>[Your, palm, is, too, far, away, from, the, ai...</td>\n",
       "      <td>[B-Event, I-Event, I-Event, I-Event, I-Event, ...</td>\n",
       "      <td>[NonEvent, Event]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>578 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence  \\\n",
       "0    [(A, B-Event), (passenger, I-Event), (aircraft...   \n",
       "1    [(A, B-Event), (passenger, I-Event), (aircraft...   \n",
       "2    [(Abnormal, B-Event), (compass, I-Event), (fun...   \n",
       "3    [(Accelerator, B-Event), (is, I-Event), (Over,...   \n",
       "4    [(Account, B-NonEvent), (not, I-NonEvent), (lo...   \n",
       "..                                                 ...   \n",
       "573  [(Your, B-Event), (aircraft, I-Event), (is, I-...   \n",
       "574  [(Your, B-Event), (aircraft, I-Event), (is, I-...   \n",
       "575  [(Your, B-Event), (aircraft, I-Event), (is, I-...   \n",
       "576  [(Your, B-Event), (palm, I-Event), (is, I-Even...   \n",
       "577  [(Your, B-Event), (palm, I-Event), (is, I-Even...   \n",
       "\n",
       "                                                tokens  \\\n",
       "0    [A, passenger, aircraft, is, approaching, ., D...   \n",
       "1    [A, passenger, aircraft, is, nearby, ., Fly, w...   \n",
       "2    [Abnormal, compass, function, or, GPS, signal,...   \n",
       "3                    [Accelerator, is, Over, Range, .]   \n",
       "4    [Account, not, logged, in, ., Flight, altitude...   \n",
       "..                                                 ...   \n",
       "573  [Your, aircraft, is, at, the, boundary, of, an...   \n",
       "574  [Your, aircraft, is, at, the, boundary, of, an...   \n",
       "575  [Your, aircraft, is, flying, in, an, Altitude,...   \n",
       "576  [Your, palm, is, too, close, to, the, aircraft...   \n",
       "577  [Your, palm, is, too, far, away, from, the, ai...   \n",
       "\n",
       "                                                  tags       entity_types  \n",
       "0    [B-Event, I-Event, I-Event, I-Event, E-Event, ...  [NonEvent, Event]  \n",
       "1    [B-Event, I-Event, I-Event, I-Event, E-Event, ...  [NonEvent, Event]  \n",
       "2    [B-Event, I-Event, I-Event, I-Event, I-Event, ...            [Event]  \n",
       "3              [B-Event, I-Event, I-Event, E-Event, O]            [Event]  \n",
       "4    [B-NonEvent, I-NonEvent, I-NonEvent, E-NonEven...  [NonEvent, Event]  \n",
       "..                                                 ...                ...  \n",
       "573  [B-Event, I-Event, I-Event, I-Event, I-Event, ...  [NonEvent, Event]  \n",
       "574  [B-Event, I-Event, I-Event, I-Event, I-Event, ...  [NonEvent, Event]  \n",
       "575  [B-Event, I-Event, I-Event, I-Event, I-Event, ...  [NonEvent, Event]  \n",
       "576  [B-Event, I-Event, I-Event, I-Event, I-Event, ...  [NonEvent, Event]  \n",
       "577  [B-Event, I-Event, I-Event, I-Event, I-Event, ...  [NonEvent, Event]  \n",
       "\n",
       "[578 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract all entity types for each sentence\n",
    "def extract_entity_types(sentence):\n",
    "    entity_types = set(tag.split('-')[-1] for _, tag in sentence if tag != 'O')\n",
    "    return list(entity_types)  # Convert to list to represent as multilabels\n",
    "\n",
    "# Prepare a structured dataset\n",
    "data = []\n",
    "for sentence in sentences:\n",
    "    tokens = [token for token, tag in sentence]\n",
    "    tags = [tag for token, tag in sentence]\n",
    "    entity_types = extract_entity_types(sentence)  # List of unique entity types\n",
    "    # sentence = \" \".join(tokens)\n",
    "    data.append({\n",
    "        'sentence': sentence,\n",
    "        'tokens': tokens,\n",
    "        'tags': tags,\n",
    "        'entity_types': entity_types  # Multilabels\n",
    "    })\n",
    "\n",
    "# Convert to a DataFrame for easier manipulation\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Encode Multilabels for Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting iterative-stratification\n",
      "  Downloading iterative_stratification-0.1.9-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\sward\\.conda\\envs\\adfler\\lib\\site-packages (from iterative-stratification) (2.0.2)\n",
      "Collecting scipy (from iterative-stratification)\n",
      "  Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scikit-learn (from iterative-stratification)\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->iterative-stratification)\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->iterative-stratification)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading iterative_stratification-0.1.9-py3-none-any.whl (8.5 kB)\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 35.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 36.2 MB/s eta 0:00:00\n",
      "Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 9.2/44.5 MB 43.9 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 11.8/44.5 MB 28.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 14.9/44.5 MB 22.9 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 17.0/44.5 MB 20.7 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 19.9/44.5 MB 18.8 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 22.5/44.5 MB 18.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 25.7/44.5 MB 17.1 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 28.3/44.5 MB 16.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 30.4/44.5 MB 15.7 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 31.7/44.5 MB 14.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 32.8/44.5 MB 13.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 34.1/44.5 MB 13.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 35.4/44.5 MB 12.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 37.0/44.5 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 38.3/44.5 MB 11.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 40.1/44.5 MB 11.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 41.7/44.5 MB 11.4 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 43.3/44.5 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 10.9 MB/s eta 0:00:00\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn, iterative-stratification\n",
      "Successfully installed iterative-stratification-0.1.9 joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip install iterative-stratification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedShuffleSplit\n",
    "\n",
    "# Convert the list of entity types to a multilabel binary indicator matrix\n",
    "mlb = MultiLabelBinarizer()\n",
    "entity_type_matrix = mlb.fit_transform(df['entity_types'])\n",
    "\n",
    "# Add the matrix as a new DataFrame for easy splitting\n",
    "entity_type_df = pd.DataFrame(entity_type_matrix, columns=mlb.classes_)\n",
    "df = pd.concat([df, entity_type_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Perform Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train distribution: Event       0.908867\n",
      "NonEvent    0.512315\n",
      "dtype: float64\n",
      "Test distribution: Event       0.924419\n",
      "NonEvent    0.517442\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Set up the stratified multilabel split\n",
    "msss = MultilabelStratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "\n",
    "# Perform the split\n",
    "for train_idx, test_idx in msss.split(df, entity_type_matrix):\n",
    "    train_df = df.iloc[train_idx]\n",
    "    test_df = df.iloc[test_idx]\n",
    "\n",
    "# Check distribution of entity types in train and test sets\n",
    "print(\"Train distribution:\", train_df[mlb.classes_].mean())\n",
    "print(\"Test distribution:\", test_df[mlb.classes_].mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Save the Split Data Back to CoNLL Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_conll(dataframe, file_path):\n",
    "    with open(file_path, 'w') as file:\n",
    "        for _, row in dataframe.iterrows():\n",
    "            sentence = row['sentence']\n",
    "            for token, tag in sentence:\n",
    "                file.write(f\"{token} {tag}\\n\")\n",
    "            file.write(\"\\n\")  # Blank line between sentences\n",
    "\n",
    "# Save the train and test sets\n",
    "save_to_conll(train_df, \"train_conll_data.txt\")\n",
    "save_to_conll(test_df, \"test_conll_data.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Verify the Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original distribution: Event       0.913495\n",
      "NonEvent    0.513841\n",
      "dtype: float64\n",
      "Train distribution: Event       0.908867\n",
      "NonEvent    0.512315\n",
      "dtype: float64\n",
      "Test distribution: Event       0.924419\n",
      "NonEvent    0.517442\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Original dataset distribution for comparison\n",
    "original_distribution = df[mlb.classes_].mean()\n",
    "print(\"Original distribution:\", original_distribution)\n",
    "\n",
    "train_distribution = train_df[mlb.classes_].mean()\n",
    "test_distribution = test_df[mlb.classes_].mean()\n",
    "\n",
    "print(\"Train distribution:\", train_distribution)\n",
    "print(\"Test distribution:\", test_distribution)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ADFLER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
