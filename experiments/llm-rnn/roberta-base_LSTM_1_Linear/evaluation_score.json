{
    "boundary": {
        "precision": 0.901840490797546,
        "recall": 0.9423076923076923,
        "num_correct": 294,
        "num_predicted": 326,
        "num_true": 312,
        "f1": 0.9216300940438872
    },
    "classification": {
        "precision": 0.9479166666666666,
        "recall": 0.9333333333333333,
        "f1": 0.9405684754521964,
        "accuracy": 0.9217687074829932,
        "support": 294
    },
    "scenario_args": {
        "model_type": "roberta",
        "model_name_or_path": "roberta-base",
        "encoder": "lstm",
        "max_seq_length": 128,
        "num_layers": 1,
        "train_batch_size": 16,
        "eval_batch_size": 16,
        "learning_rate": 2e-05,
        "train_epochs": 10,
        "scenario": "llm-rnn",
        "output_dir": "experiments/llm-rnn/roberta-base_LSTM_1_Linear",
        "use_crf": false,
        "bidirectional": false,
        "seed": 42,
        "save_model": false
    }
}